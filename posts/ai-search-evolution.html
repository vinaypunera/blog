<!DOCTYPE html><!--gqZ7jiqpf8fvmPoRYqmpx--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/4cf2300e9c8272f7-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/93f479601ee12b01-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/illustrations/ai-search-evolution.svg"/><link rel="stylesheet" href="/_next/static/css/de204d2dcad441e1.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-ed9be09274cd6fae.js"/><script src="/_next/static/chunks/4bd1b696-182b6b13bdad92e3.js" async=""></script><script src="/_next/static/chunks/1255-2c359fbdcbebe457.js" async=""></script><script src="/_next/static/chunks/main-app-1d81304c46a54c0f.js" async=""></script><script src="/_next/static/chunks/2201-6f6797369dbd70e4.js" async=""></script><script src="/_next/static/chunks/8005-36f473f8046dae16.js" async=""></script><script src="/_next/static/chunks/7750-0a756454837a9a28.js" async=""></script><script src="/_next/static/chunks/9227-702d20ddd5580687.js" async=""></script><script src="/_next/static/chunks/app/layout-1292cda0e395339b.js" async=""></script><script src="/_next/static/chunks/1356-1fb83b63ccda55b7.js" async=""></script><script src="/_next/static/chunks/app/posts/%5Bslug%5D/page-9925e7bd02be95a8.js" async=""></script><meta name="next-size-adjust" content=""/><title>Beyond the Keyword: How AI Taught Search to Understand You</title><meta name="description" content="We&#x27;ve all been there: you search for &#x27;soda&#x27; but the app only knows &#x27;pop&#x27;. This is the search problem. Let&#x27;s go on a journey from simple keyword counting (TF-IDF) to smarter ranking (BM25) and finally to AI that gets you (SPLADE)."/><meta property="og:title" content="Beyond the Keyword: How AI Taught Search to Understand You"/><meta property="og:description" content="We&#x27;ve all been there: you search for &#x27;soda&#x27; but the app only knows &#x27;pop&#x27;. This is the search problem. Let&#x27;s go on a journey from simple keyword counting (TF-IDF) to smarter ranking (BM25) and finally to AI that gets you (SPLADE)."/><meta property="og:image" content="https://vinay.stealthbit.in/illustrations/ai-search-evolution.svg"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="An abstract image showing a simple keyword &#x27;pop&#x27; evolving into a complex, connected concept of &#x27;soda&#x27; and &#x27;beverage&#x27;."/><meta property="og:type" content="article"/><meta property="article:published_time" content="2025-11-14T00:00:00.000Z"/><meta property="article:tag" content="ai-search"/><meta property="article:tag" content="splade"/><meta property="article:tag" content="bm25"/><meta property="article:tag" content="tf-idf"/><meta property="article:tag" content="vectors"/><meta property="article:tag" content="sparse-vectors"/><meta property="article:tag" content="dense-vectors"/><meta property="article:tag" content="qdrant"/><meta property="article:tag" content="rag"/><meta property="article:tag" content="nlp"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Beyond the Keyword: How AI Taught Search to Understand You"/><meta name="twitter:description" content="We&#x27;ve all been there: you search for &#x27;soda&#x27; but the app only knows &#x27;pop&#x27;. This is the search problem. Let&#x27;s go on a journey from simple keyword counting (TF-IDF) to smarter ranking (BM25) and finally to AI that gets you (SPLADE)."/><meta name="twitter:image" content="https://vinay.stealthbit.in/illustrations/ai-search-evolution.svg"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><link rel="icon" href="/icon.svg?b0cfa693b1818954" type="image/svg+xml" sizes="any"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_188709 __variable_9a8899 min-h-screen bg-background font-sans text-foreground"><div hidden=""><!--$--><!--/$--></div><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><style>#nprogress{pointer-events:none}#nprogress .bar{background:hsl(var(--accent));position:fixed;z-index:1600;top: 0;left:0;width:100%;height:3px}#nprogress .peg{display:block;position:absolute;right:0;width:100px;height:100%;box-shadow:0 0 10px hsl(var(--accent)),0 0 5px hsl(var(--accent));opacity:1;-webkit-transform:rotate(3deg) translate(0px,-4px);-ms-transform:rotate(3deg) translate(0px,-4px);transform:rotate(3deg) translate(0px,-4px)}#nprogress .spinner{display:block;position:fixed;z-index:1600;top: 15px;right:15px}#nprogress .spinner-icon{width:18px;height:18px;box-sizing:border-box;border:2px solid transparent;border-top-color:hsl(var(--accent));border-left-color:hsl(var(--accent));border-radius:50%;-webkit-animation:nprogress-spinner 400ms linear infinite;animation:nprogress-spinner 400ms linear infinite}.nprogress-custom-parent{overflow:hidden;position:relative}.nprogress-custom-parent #nprogress .bar,.nprogress-custom-parent #nprogress .spinner{position:absolute}@-webkit-keyframes nprogress-spinner{0%{-webkit-transform:rotate(0deg)}100%{-webkit-transform:rotate(360deg)}}@keyframes nprogress-spinner{0%{transform:rotate(0deg)}100%{transform:rotate(360deg)}}</style><div class="pointer-events-none fixed bottom-6 right-6 z-50 flex flex-col items-end gap-3 sm:bottom-10 sm:right-10"><div class="pointer-events-auto flex flex-col items-end gap-3"><div class="flex items-center gap-3"><div class="pointer-events-auto flex items-center rounded-full bg-background/95 shadow-xl backdrop-blur-sm ring-1 ring-border/50 floating-player-glow"><button type="button" class="flex h-14 w-14 shrink-0 items-center justify-center rounded-full bg-accent text-accent-foreground shadow-2xl transition hover:bg-accent/90" aria-label="Open navigation"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu h-6 w-6" aria-hidden="true"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg></button></div></div></div></div><div class="flex min-h-screen flex-col"><main class="flex-1"><div class="pointer-events-none fixed top-0 left-0 z-40 h-1 w-full bg-transparent"><div class="h-full bg-accent transition-[width] duration-200" style="width:0%" role="presentation" aria-hidden="true"></div></div><article class="mx-auto flex w-full max-w-3xl flex-col gap-10 px-6 pt-12 pb-28"><nav aria-label="Breadcrumb"><ol class="flex flex-wrap items-center gap-1 text-sm text-muted-foreground"><li class="flex items-center gap-1"><a class="hover:text-accent" href="/">Home</a><span aria-hidden="true">/</span></li><li class="flex items-center gap-1"><a class="hover:text-accent" href="/#posts">Posts</a><span aria-hidden="true">/</span></li><li class="flex items-center gap-1"><a class="hover:text-accent" href="/posts/ai-search-evolution">Beyond the Keyword: How AI Taught Search to Understand You</a></li></ol></nav><header class="space-y-4"><p class="text-xs uppercase tracking-[0.3em] text-accent">Article</p><h1 class="text-3xl font-semibold leading-tight sm:text-4xl">Beyond the Keyword: How AI Taught Search to Understand You</h1><div class="flex flex-wrap items-center gap-3 text-sm text-muted-foreground"><time dateTime="2025-11-14T00:00:00.000Z">Nov 14, 2025</time><span aria-hidden="true">‚Ä¢</span><span>11 min read</span><span aria-hidden="true">‚Ä¢</span><a class="font-medium text-foreground transition-colors hover:text-accent" href="/about">Vinay Punera</a></div><div class="flex flex-wrap gap-2"><span class="rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide">ai-search</span><span class="rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide">splade</span><span class="rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide">bm25</span><span class="rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide">tf-idf</span><span class="rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide">vectors</span><span class="rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide">sparse-vectors</span><span class="rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide">dense-vectors</span><span class="rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide">qdrant</span><span class="rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide">rag</span><span class="rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide">nlp</span></div></header><section aria-label="Listen to this post" class="rounded-3xl border border-border bg-muted/50 p-4 shadow-sm transition-all"><div class="flex items-center gap-3"><button type="button" aria-label="Play narration" class="flex h-11 w-11 shrink-0 items-center justify-center rounded-full bg-accent text-white shadow-sm transition hover:bg-accent/90"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-play h-4 w-4 transition" aria-hidden="true"><polygon points="6 3 20 12 6 21 6 3"></polygon></svg></button><div class="flex min-w-0 flex-1 flex-col gap-1"><span class="flex items-center gap-2 text-[11px] font-semibold uppercase tracking-[0.3em] text-muted-foreground">Listen</span><span class="truncate text-sm font-medium text-foreground">AI narration</span></div></div><div class="mt-3 flex items-center gap-2"><span class="shrink-0 text-xs tabular-nums text-muted-foreground">0:00</span><div class="relative h-6 flex-1 select-none focus-within:outline-none"><div class="absolute left-0 right-0 top-1/2 h-1 -translate-y-1/2 overflow-hidden rounded-full bg-border"><div class="h-full rounded-full bg-accent transition-all" style="width:0%"></div></div><input type="range" min="0" max="300" step="any" aria-label="Scrub through the narration" aria-valuetext="0:00 of 05:00" disabled="" class="absolute inset-0 m-0 h-full w-full cursor-pointer appearance-none bg-transparent disabled:cursor-not-allowed [&amp;::-webkit-slider-runnable-track]:appearance-none [&amp;::-moz-range-track]:bg-transparent [&amp;::-webkit-slider-thumb]:appearance-none [&amp;::-webkit-slider-thumb]:h-4 [&amp;::-webkit-slider-thumb]:w-4 [&amp;::-webkit-slider-thumb]:rounded-full [&amp;::-webkit-slider-thumb]:bg-white [&amp;::-webkit-slider-thumb]:shadow-[0_0_0.75rem_hsl(var(--accent)_/_0.25)] [&amp;::-webkit-slider-thumb]:transition [&amp;::-moz-range-thumb]:h-4 [&amp;::-moz-range-thumb]:w-4 [&amp;::-moz-range-thumb]:appearance-none [&amp;::-moz-range-thumb]:rounded-full [&amp;::-moz-range-thumb]:border-0 [&amp;::-moz-range-thumb]:bg-white [&amp;::-moz-range-thumb]:shadow-[0_0_0.75rem_hsl(var(--accent)_/_0.25)] [&amp;::-moz-range-thumb]:transition" value="0"/></div><span class="shrink-0 text-xs tabular-nums text-muted-foreground">05:00</span></div></section><div class="overflow-hidden rounded-3xl border border-border bg-muted"><img alt="An abstract image showing a simple keyword &#x27;pop&#x27; evolving into a complex, connected concept of &#x27;soda&#x27; and &#x27;beverage&#x27;." width="1200" height="630" decoding="async" data-nimg="1" class="h-auto w-full object-cover" style="color:transparent" src="/illustrations/ai-search-evolution.svg"/></div><div class="prose prose-neutral dark:prose-invert max-w-none"><div><p>We've all screamed at our search bars, right?</p>
<p>That feeling when you search for "soda" and get zero results, just because the file you <em>know</em> is in there says "pop." Or you search for "laptop with a good graphics card" and the search just shows you every single "laptop" and every single "graphics card" in the store, but not the <em>one</em> you want.</p>
<p>This is the <strong>search problem</strong>. For decades, we've been trying to get computers to just... <em>get</em> us. To understand what we <em>mean</em>, not just what we <em>type</em>.</p>
<p>This isn't a single "aha!" moment; it's an evolutionary journey. We're going to walk that path together, from a "Dumb Counter" to a "Smart Sorter" and finally to an "AI Mind Reader." This is the story of how search evolved from <strong>TF-IDF</strong> to <strong>BM25</strong> to <strong>SPLADE</strong>.</p>
<hr>
<h3>üìö Chapter 1: The "Dumb Counter" Librarian (TF-IDF)</h3>
<p>In the beginning, we had <strong>TF-IDF (Term Frequency-Inverse Document Frequency)</strong>.</p>
<p>It's a very clever, very mathematical way of finding keywords, but let's think of it as a librarian who's super fast but... not very smart. This librarian finds books for you by following two simple rules:</p>
<ol>
<li>
<p><strong>Term Frequency (TF):</strong> How many times is my word in <em>this</em> book?</p>
<ul>
<li><strong>The logic:</strong> "You searched for 'dragon.' This book mentions 'dragon' 50 times. This other one mentions it once. You probably want the first book." Simple enough.</li>
</ul>
</li>
<li>
<p><strong>Inverse Document Frequency (IDF):</strong> How <em>special</em> is this word in the <em>whole library</em>?</p>
<ul>
<li><strong>The logic:</strong> This is the clever part. The word "the" is in <em>every</em> book. It's not special at all, so it gets a "specialness" score of 0. But a word like "gorgonzola" is only in a few books. It's super special! It gets a high score.</li>
</ul>
</li>
</ol>
<p>The TF-IDF score is just <strong>TF √ó IDF</strong>. This means a word is "important" if it's <strong>common in this one book</strong> but <strong>rare in the rest of the library</strong>.</p>
<p>For its time, this was genius. But it had <em>huge</em>, game-breaking flaws.</p>
<ul>
<li><strong>The "Keyword Stuffing" Flaw:</strong> What if a spammer just wrote "CHEAP LAPTOP CHEAP LAPTOP" 1,000 times? Our "Dumb Counter" librarian would think, "WOW! This must be the <em>best document ever</em> on cheap laptops!" It's easily fooled by spam.</li>
<li><strong>The "Length" Flaw:</strong> A 1,000-page encyclopedia that mentions "raven" 10 times would get a higher score than a 1-page poem <em>named</em> "The Raven" that mentions it 5 times. The encyclopedia has more mentions, but the poem is <em>clearly</em> more about ravens. TF-IDF just couldn't figure that out.</li>
</ul>
<p>We needed a librarian that wasn't just fast, but <em>smarter</em>.</p>
<h4>üìä How TF-IDF Works</h4>
<p>Here's a visual representation of TF-IDF's simple counting approach:</p>
<figure class="mermaid-diagram"><img src="/diagrams/ai-search-evolution-diagram-1.svg" alt="Diagram 1"></figure>
<p>The problem is clear: if the exact word "soda" doesn't appear, the document gets a score of zero. No understanding, just counting.</p>
<hr>
<h3>üèÜ Chapter 2: The "Smart Sorter" Librarian (BM25)</h3>
<p>This is the "Glow-Up" of TF-IDF. <strong>BM25 (Best Matching 25)</strong> is the algorithm that powered almost every major search engine for decades. It's the default for most databases today, and for good reason: it's a <em>phenomenally</em> smart sorter.</p>
<p>BM25 is basically TF-IDF's kid who went to college and learned from its parent's mistakes. It fixes the two big flaws perfectly.</p>
<ol>
<li>
<p><strong>The Fix for "Keyword Stuffing" (Term Saturation):</strong>
BM25 is like a friend who gets bored easily.</p>
<ul>
<li>The <em>first</em> time you say "laptop," it's super interested (big score boost!).</li>
<li>The <em>fifth</em> time, it's like, "Yeah, I get it, 'laptop'" (a much smaller boost).</li>
<li>The <em>100th</em> time, it's just ignoring you (zero extra score).
This scoring curve "saturates," which makes keyword stuffing totally pointless. Problem solved.</li>
</ul>
</li>
<li>
<p><strong>The Fix for "Length" (Length Normalization):</strong>
BM25 is aware. It starts by calculating the <em>average document length</em> of the whole collection. It knows the "average" document is, say, 300 words.</p>
<ul>
<li>So, when it sees the 1-page poem (100 words) with 5 "raven" mentions, it thinks, "Whoa! 5 mentions in <em>such a short document</em>? This must be <em>insanely</em> relevant!"</li>
<li>When it sees the 1,000-page encyclopedia, it thinks, "Only 10 'raven' mentions in a doc this huge? Meh."
It "normalizes" the score, giving the short, concise poem the win.</li>
</ul>
</li>
</ol>
<p>BM25 was king for a very long time. It's fast, efficient, and gives great results.</p>
<p>...But it <em>still</em> had that one, fundamental, dumb problem. It's just a counter. A <em>really, really smart</em> counter, but still a counter. It has no idea what words <em>mean</em>.</p>
<p>If you search for "<strong>soda</strong>," it will <em>never</em> match "<strong>pop</strong>."
If you search for "<strong>beverage for a party</strong>," it will <em>never</em> match "<strong>drinks for a celebration</strong>."</p>
<p>To solve this, we had to leave the world of "counting" and enter the world of "understanding." We had to bring in AI.</p>
<h4>üìä How BM25 Improves Upon TF-IDF</h4>
<p>Here's how BM25's smart weighting works:</p>
<figure class="mermaid-diagram"><img src="/diagrams/ai-search-evolution-diagram-2.svg" alt="Diagram 2"></figure>
<p>BM25 is smarter, but it still can't connect "soda" with "pop" conceptually!</p>
<hr>
<h3>ü§ñ Chapter 3: The "AI Mind Reader" (SPLADE)</h3>
<p>This is the new frontier of <strong>Learned Sparse Retrieval (LSR)</strong>. Its most famous and effective model: <strong>SPLADE (Sparse Lexical and Expansion Model)</strong>.</p>
<p>This is a total game-changer. SPLADE is built on a <strong>Transformer AI model (specifically, the BERT architecture)</strong>. This AI has read basically the entire internet. It doesn't just know words; it knows <em>concepts</em>.</p>
<p>Here's the magic, step-by-step:</p>
<ol>
<li><strong>Core Mechanism:</strong> SPLADE leverages the <strong>Masked Language Modeling (MLM)</strong> head of BERT. This is the part of the model that's trained to fill in the blanks, which forces it to understand the context of every single word.</li>
<li><strong>Understand &#x26; Expand:</strong> Instead of discarding the MLM head, SPLADE uses it to predict the relevance of <em>every</em> word in its vocabulary (around 30,000 terms) based on the input document. When you give it "A guide to French cheese," the model <em>expands</em> the term list to include all related concepts it learned: 'brie', 'camembert', 'gourmet', 'wine', etc.</li>
<li><strong>Prune &#x26; Sparsify:</strong> Here's the genius part (the "Sparse" in SPLADE): the model is trained with strong regularization to be a minimalist. It forces the scores of 99%+ of the vocabulary to be <strong>zero</strong>, leaving behind <em>only</em> the absolute most important and descriptive "tags" for this document.</li>
</ol>
<p>The result is a <strong>"Smart Tag Cloud."</strong></p>
<ul>
<li>A <strong>BM25</strong> "tag cloud" for that doc would just be: <code>[guide, french, cheese]</code></li>
<li>A <strong>SPLADE</strong> "tag cloud" (its sparse vector) would be: <code>[guide, french, cheese, brie, camembert, gourmet, wine, dairy]</code></li>
</ul>
<p>Now... when your user searches for "<strong>best brie recipe</strong>," SPLADE sees a match! Your document is found, even though it <em>never</em> contained the word "brie." The vocabulary mismatch problem is finally solved.</p>
<h4>üìå Not the Only Player: Learned Sparse Retrieval (LSR)</h4>
<p>While SPLADE is the most widely adopted, it is part of a broader, active research field called <strong>Learned Sparse Retrieval (LSR)</strong>. Other notable models you might encounter include <strong>uniCOIL</strong> and <strong>DeepImpact</strong>. They all aim to achieve the same goal - neural-powered keyword search - but differ slightly in their training and approach (e.g., DeepImpact often expands documents <em>before</em> applying the learned scores, while SPLADE does it end-to-end).</p>
<h4>üìä How SPLADE Expands Your Query</h4>
<p>Let's visualize how SPLADE transforms a simple query into a rich concept map:</p>
<figure class="mermaid-diagram"><img src="/diagrams/ai-search-evolution-diagram-3.svg" alt="Diagram 3"></figure>
<p>Notice how SPLADE not only keeps the original terms ("french", "cheese") but intelligently adds related concepts ("brie", "camembert", "gourmet", "dairy", "wine") with appropriate weights. The higher the weight, the more important the term is to understanding the query.</p>
<hr>
<h3>üí° Wait... Why Not Just Use "AI Search" (Dense Vectors)?</h3>
<p>This is the central question. You've heard "semantic search" and "dense vectors." If SPLADE uses AI, and semantic search uses AI, aren't they the same?</p>
<p>Nope! They are two different AI strategies, good at <em>opposite</em> things.</p>
<ul>
<li>
<p><strong>Dense Vectors (Semantic Search):</strong></p>
<ul>
<li><strong>Analogy:</strong> A "GPS Coordinate" for meaning, or a "Vibe Check."</li>
<li><strong>How it works:</strong> It takes your <em>whole</em> document and squashes its <em>entire</em> meaning into a list of ~768 numbers, like <code>[0.1, -0.4, 0.9, ...]</code>.</li>
<li><strong>Good at:</strong> Finding <em>holistic concepts</em>. It knows "sad songs" is close to "lyrics about a broken heart." It's great at finding the "vibe."</li>
<li><strong>Bad at:</strong> <em>Specificity</em>. It "averages out" the meaning. If you search for a specific product ID like "<strong>SKU-ABC-123</strong>," the dense vector just sees "some product ID" and gets confused. It <em>loses</em> the specific keyword.</li>
</ul>
</li>
<li>
<p><strong>SPLADE (Learned Sparse Search):</strong></p>
<ul>
<li><strong>Analogy:</strong> A "Smart Tag Cloud" or an "AI-powered Index."</li>
<li><strong>How it works:</strong> It creates a huge list (~30,000 slots) that is <em>mostly zeros</em> but has high scores on <em>very specific</em> keywords, including its smart expansions.</li>
<li><strong>Good at:</strong> <em>Precision</em>. It <em>loves</em> specific keywords. It will see "<strong>SKU-ABC-123</strong>" and put a <em>massive</em> importance score on that <em>exact</em> term, making it impossible to miss.</li>
<li><strong>Bad at:</strong> Vague "vibes." A search for "that feeling you get on a rainy day" would be hard for SPLADE, but easy for a dense vector.</li>
</ul>
</li>
</ul>
<p>The ultimate setup isn't one or the other. It's <strong>Hybrid Search</strong>: using <em>both</em> at the same time. You get the "vibe" search from dense vectors and the "precision" search from SPLADE.</p>
<hr>
<h3>üì¶ Putting It All Together in Your Vector DB</h3>
<p>This is where a modern vector database like <strong>Qdrant</strong> becomes so powerful. It's <em>designed</em> for this new, hybrid world. It doesn't force you to choose.</p>
<h4>üîÑ How Hybrid Search Works</h4>
<p>Here's how Qdrant executes a hybrid search, combining dense and sparse vectors with RRF fusion:</p>
<figure class="mermaid-diagram"><img src="/diagrams/ai-search-evolution-diagram-4.svg" alt="Diagram 4"></figure>
<p>The beauty of hybrid search is that it runs both searches in parallel, then intelligently combines the results. Documents that appear highly ranked in <em>both</em> searches get a significant boost, ensuring you get the most relevant results.</p>
<hr>
<h3>üéØ Beyond Retrieval: The Final Step is Reranking</h3>
<p>You now have a Hybrid Search system that is both broad (high <strong>Recall</strong> from Dense) and specific (high <strong>Precision</strong> from Sparse). This is called <strong>First-Stage Retrieval</strong> - you've successfully identified a short list of, say, 50 potential documents.</p>
<p>But for a true production-grade system (especially for Retrieval-Augmented Generation, or RAG), we need one more step: <strong>Reranking</strong>.</p>
<p>Reranking is the quality control filter. It is done by a highly accurate but slow model called a <strong>Cross-Encoder</strong>.</p>






























<table><thead><tr><th align="left">Concept</th><th align="left">The Analogy</th><th align="left">The Technical Difference</th></tr></thead><tbody><tr><td align="left"><strong>First-Stage Models</strong> (Dense/SPLADE)</td><td align="left"><strong>The Matchmaker:</strong> They look at your query and your document <strong>separately</strong>, scoring them only on vector similarity. Fast, but lacks nuance.</td><td align="left"><strong>Separate Encoding:</strong> Query and Document are encoded into vectors independently.</td></tr><tr><td align="left"><strong>The Problem</strong></td><td align="left"><strong>Query:</strong> "Why is <strong>brie</strong> the best cheese for <strong>wine</strong>?"</td><td align="left">Hybrid search might find a document that mentions <em>brie</em> highly and another that mentions <em>wine</em> highly, but misses the document that explicitly links the two.</td></tr><tr><td align="left"><strong>Reranking</strong> (Cross-Encoder)</td><td align="left"><strong>The Literary Critic:</strong> It reads your query and the document <strong>together</strong>, analyzing how every word in the query interacts with every word in the document. Slow, but highly nuanced.</td><td align="left"><strong>Joint Encoding:</strong> Query and Document are fed into the Transformer network at the same time.</td></tr><tr><td align="left"><strong>The Solution</strong></td><td align="left">The Cross-Encoder instantly sees that the document titled <em>"Pairing <strong>Brie</strong> with Chardonnay <strong>Wine</strong>"</em> is the <strong>perfect</strong> answer, even if the similarity score from the first stage wasn't the absolute highest.</td><td align="left">It correctly promotes the most contextually relevant document to the #1 spot.</td></tr></tbody></table>
<p><strong>Hybrid Search gets the candidates; Reranking picks the winner.</strong></p>
<hr>
<h3>The Journey Continues</h3>
<p>We've come a long, long way from just counting words. The "search problem" is finally being solved by combining these ideas. We started with TF-IDF (a dumb counter), got smarter with BM25 (a great sorter), and now, with AI models like SPLADE, we're teaching search to <em>understand</em> what we mean, not just what we say.</p>
<p>The future isn't dense vs. sparse. It's <em>both</em>, with a final, highly-accurate <strong>reranker</strong> to guarantee quality.</p></div></div><footer class="flex flex-col gap-6 border-t border-border pt-6"><div class="flex flex-wrap items-center gap-3"><span class="flex items-center gap-2 text-xs uppercase tracking-[0.3em] text-muted-foreground"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-share2 h-4 w-4" aria-hidden="true"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" x2="15.42" y1="13.51" y2="17.49"></line><line x1="15.41" x2="8.59" y1="6.51" y2="10.49"></line></svg>Share</span><button type="button" class="group flex h-10 w-10 items-center justify-center rounded-full border border-border transition hover:border-accent hover:bg-accent/10" aria-label="Share with device dialog"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-share2 h-4 w-4" aria-hidden="true"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" x2="15.42" y1="13.51" y2="17.49"></line><line x1="15.41" x2="8.59" y1="6.51" y2="10.49"></line></svg></button><button type="button" class="group flex h-10 w-10 items-center justify-center rounded-full border border-border transition group-hover:bg-[#0077B5] group-hover:text-white" aria-label="Share on LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-linkedin h-4 w-4" aria-hidden="true"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect width="4" height="12" x="2" y="9"></rect><circle cx="4" cy="4" r="2"></circle></svg></button><button type="button" class="group flex h-10 w-10 items-center justify-center rounded-full border border-border transition hover:border-accent hover:bg-accent/10" aria-label="Copy link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button><span class="text-xs text-accent transition-opacity duration-150 opacity-0" aria-live="polite">Link copied</span></div><p class="text-sm text-muted-foreground">Enjoyed this read? Share it with your network, or reach out via the about page for collaboration or to just say hi.</p><div class="flex flex-col gap-4 border-t border-border pt-6"><p class="text-xs uppercase tracking-[0.3em] text-muted-foreground">Keep reading</p><nav class="flex flex-col items-stretch gap-3 sm:flex-row sm:items-center sm:justify-between"><a class="group inline-flex flex-1 items-center gap-2 rounded-full border border-border px-4 py-2 text-sm transition hover:border-accent hover:text-accent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-accent" href="/posts/v8-isolates-explainer-p1"><span aria-hidden="true">‚Üê</span><span class="flex flex-col text-left"><span class="text-[11px] uppercase tracking-widest text-muted-foreground">Previous</span><span class="font-medium text-foreground group-hover:text-accent">Deep Dive into V8 and V8 Isolates: The Engine and the Sandbox (Part 1)</span></span></a><a class="group inline-flex flex-1 items-center justify-end gap-2 rounded-full border border-border px-4 py-2 text-sm transition hover:border-accent hover:text-accent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-accent sm:justify-end" href="/posts/p2p-paradox"><span class="flex flex-col text-right"><span class="text-[11px] uppercase tracking-widest text-muted-foreground">Next</span><span class="font-medium text-foreground group-hover:text-accent">The P2P Paradox: Why You Need a Server to go Serverless</span></span><span aria-hidden="true">‚Üí</span></a></nav></div></footer></article><!--$--><!--/$--></main></div><script src="/_next/static/chunks/webpack-ed9be09274cd6fae.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[51458,[\"2201\",\"static/chunks/2201-6f6797369dbd70e4.js\",\"8005\",\"static/chunks/8005-36f473f8046dae16.js\",\"7750\",\"static/chunks/7750-0a756454837a9a28.js\",\"9227\",\"static/chunks/9227-702d20ddd5580687.js\",\"7177\",\"static/chunks/app/layout-1292cda0e395339b.js\"],\"ThemeProvider\"]\n3:I[21887,[\"2201\",\"static/chunks/2201-6f6797369dbd70e4.js\",\"8005\",\"static/chunks/8005-36f473f8046dae16.js\",\"7750\",\"static/chunks/7750-0a756454837a9a28.js\",\"9227\",\"static/chunks/9227-702d20ddd5580687.js\",\"7177\",\"static/chunks/app/layout-1292cda0e395339b.js\"],\"\"]\n4:I[79081,[\"2201\",\"static/chunks/2201-6f6797369dbd70e4.js\",\"8005\",\"static/chunks/8005-36f473f8046dae16.js\",\"7750\",\"static/chunks/7750-0a756454837a9a28.js\",\"9227\",\"static/chunks/9227-702d20ddd5580687.js\",\"7177\",\"static/chunks/app/layout-1292cda0e395339b.js\"],\"GlobalAudioProvider\"]\n5:I[80989,[\"2201\",\"static/chunks/2201-6f6797369dbd70e4.js\",\"8005\",\"static/chunks/8005-36f473f8046dae16.js\",\"7750\",\"static/chunks/7750-0a756454837a9a28.js\",\"9227\",\"static/chunks/9227-702d20ddd5580687.js\",\"7177\",\"static/chunks/app/layout-1292cda0e395339b.js\"],\"SearchSheetProvider\"]\n6:I[33572,[\"2201\",\"static/chunks/2201-6f6797369dbd70e4.js\",\"8005\",\"static/chunks/8005-36f473f8046dae16.js\",\"7750\",\"static/chunks/7750-0a756454837a9a28.js\",\"9227\",\"static/chunks/9227-702d20ddd5580687.js\",\"7177\",\"static/chunks/app/layout-1292cda0e395339b.js\"],\"FloatingAudioProvider\"]\n7:I[87435,[\"2201\",\"static/chunks/2201-6f6797369dbd70e4.js\",\"8005\",\"static/chunks/8005-36f473f8046dae16.js\",\"7750\",\"static/chunks/7750-0a756454837a9a28.js\",\"9227\",\"static/chunks/9227-702d20ddd5580687.js\",\"7177\",\"static/chunks/app/layout-1292cda0e395339b.js\"],\"FloatingNav\"]\n8:I[9766,[],\"\"]\n9:I[98924,[],\"\"]\nb:I[24431,[],\"OutletBoundary\"]\nd:I[15278,[],\"AsyncMetadataOutlet\"]\nf:I[24431,[],\"ViewportBoundary\"]\n11:I[24431,[],\"MetadataBoundary\"]\n12:\"$Sreact.suspense\"\n14:I[57150,[],\"\"]\n:HL[\"/_next/static/media/4cf2300e9c8272f7-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/93f479601ee12b01-s.p.woff2\",\"font\",{\"cro"])</script><script>self.__next_f.push([1,"ssOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/de204d2dcad441e1.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"gqZ7jiqpf8fvmPoRYqmpx\",\"p\":\"\",\"c\":[\"\",\"posts\",\"ai-search-evolution\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"posts\",{\"children\":[[\"slug\",\"ai-search-evolution\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/de204d2dcad441e1.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"className\":\"__variable_188709 __variable_9a8899 min-h-screen bg-background font-sans text-foreground\",\"children\":[\"$\",\"$L2\",null,{\"children\":[[\"$\",\"$L3\",null,{\"color\":\"hsl(var(--accent))\",\"height\":3,\"showSpinner\":false}],[\"$\",\"$L4\",null,{\"children\":[\"$\",\"$L5\",null,{\"children\":[\"$\",\"$L6\",null,{\"children\":[[\"$\",\"$L7\",null,{}],[\"$\",\"div\",null,{\"className\":\"flex min-h-screen flex-col\",\"children\":[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L9\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}]}]}]]}]}]}]]}],{\"children\":[\"posts\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L9\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"ai-search-evolution\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L9\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$La\",null,[\"$\",\"$Lb\",null,{\"children\":[\"$Lc\",[\"$\",\"$Ld\",null,{\"promise\":\"$@e\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$L11\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$12\",null,{\"fallback\":null,\"children\":\"$L13\"}]}]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$14\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"15:I[19558,[\"2201\",\"static/chunks/2201-6f6797369dbd70e4.js\",\"1356\",\"static/chunks/1356-1fb83b63ccda55b7.js\",\"8005\",\"static/chunks/8005-36f473f8046dae16.js\",\"5858\",\"static/chunks/app/posts/%5Bslug%5D/page-9925e7bd02be95a8.js\"],\"MarkPostRead\"]\n16:I[7553,[\"2201\",\"static/chunks/2201-6f6797369dbd70e4.js\",\"1356\",\"static/chunks/1356-1fb83b63ccda55b7.js\",\"8005\",\"static/chunks/8005-36f473f8046dae16.js\",\"5858\",\"static/chunks/app/posts/%5Bslug%5D/page-9925e7bd02be95a8.js\"],\"ReadingProgress\"]\n17:I[52619,[\"2201\",\"static/chunks/2201-6f6797369dbd70e4.js\",\"1356\",\"static/chunks/1356-1fb83b63ccda55b7.js\",\"8005\",\"static/chunks/8005-36f473f8046dae16.js\",\"5858\",\"static/chunks/app/posts/%5Bslug%5D/page-9925e7bd02be95a8.js\"],\"\"]\n18:I[66078,[\"2201\",\"static/chunks/2201-6f6797369dbd70e4.js\",\"1356\",\"static/chunks/1356-1fb83b63ccda55b7.js\",\"8005\",\"static/chunks/8005-36f473f8046dae16.js\",\"5858\",\"static/chunks/app/posts/%5Bslug%5D/page-9925e7bd02be95a8.js\"],\"PostAudioPlayer\"]\n19:I[24121,[\"2201\",\"static/chunks/2201-6f6797369dbd70e4.js\",\"1356\",\"static/chunks/1356-1fb83b63ccda55b7.js\",\"8005\",\"static/chunks/8005-36f473f8046dae16.js\",\"5858\",\"static/chunks/app/posts/%5Bslug%5D/page-9925e7bd02be95a8.js\"],\"MermaidDiagrams\"]\n1a:I[81356,[\"2201\",\"static/chunks/2201-6f6797369dbd70e4.js\",\"1356\",\"static/chunks/1356-1fb83b63ccda55b7.js\",\"8005\",\"static/chunks/8005-36f473f8046dae16.js\",\"5858\",\"static/chunks/app/posts/%5Bslug%5D/page-9925e7bd02be95a8.js\"],\"Image\"]\n1b:T3a2a,"])</script><script>self.__next_f.push([1,"\u003cp\u003eWe've all screamed at our search bars, right?\u003c/p\u003e\n\u003cp\u003eThat feeling when you search for \"soda\" and get zero results, just because the file you \u003cem\u003eknow\u003c/em\u003e is in there says \"pop.\" Or you search for \"laptop with a good graphics card\" and the search just shows you every single \"laptop\" and every single \"graphics card\" in the store, but not the \u003cem\u003eone\u003c/em\u003e you want.\u003c/p\u003e\n\u003cp\u003eThis is the \u003cstrong\u003esearch problem\u003c/strong\u003e. For decades, we've been trying to get computers to just... \u003cem\u003eget\u003c/em\u003e us. To understand what we \u003cem\u003emean\u003c/em\u003e, not just what we \u003cem\u003etype\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eThis isn't a single \"aha!\" moment; it's an evolutionary journey. We're going to walk that path together, from a \"Dumb Counter\" to a \"Smart Sorter\" and finally to an \"AI Mind Reader.\" This is the story of how search evolved from \u003cstrong\u003eTF-IDF\u003c/strong\u003e to \u003cstrong\u003eBM25\u003c/strong\u003e to \u003cstrong\u003eSPLADE\u003c/strong\u003e.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3\u003eüìö Chapter 1: The \"Dumb Counter\" Librarian (TF-IDF)\u003c/h3\u003e\n\u003cp\u003eIn the beginning, we had \u003cstrong\u003eTF-IDF (Term Frequency-Inverse Document Frequency)\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eIt's a very clever, very mathematical way of finding keywords, but let's think of it as a librarian who's super fast but... not very smart. This librarian finds books for you by following two simple rules:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eTerm Frequency (TF):\u003c/strong\u003e How many times is my word in \u003cem\u003ethis\u003c/em\u003e book?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eThe logic:\u003c/strong\u003e \"You searched for 'dragon.' This book mentions 'dragon' 50 times. This other one mentions it once. You probably want the first book.\" Simple enough.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eInverse Document Frequency (IDF):\u003c/strong\u003e How \u003cem\u003especial\u003c/em\u003e is this word in the \u003cem\u003ewhole library\u003c/em\u003e?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eThe logic:\u003c/strong\u003e This is the clever part. The word \"the\" is in \u003cem\u003eevery\u003c/em\u003e book. It's not special at all, so it gets a \"specialness\" score of 0. But a word like \"gorgonzola\" is only in a few books. It's super special! It gets a high score.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThe TF-IDF score is just \u003cstrong\u003eTF √ó IDF\u003c/strong\u003e. This means a word is \"important\" if it's \u003cstrong\u003ecommon in this one book\u003c/strong\u003e but \u003cstrong\u003erare in the rest of the library\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eFor its time, this was genius. But it had \u003cem\u003ehuge\u003c/em\u003e, game-breaking flaws.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eThe \"Keyword Stuffing\" Flaw:\u003c/strong\u003e What if a spammer just wrote \"CHEAP LAPTOP CHEAP LAPTOP\" 1,000 times? Our \"Dumb Counter\" librarian would think, \"WOW! This must be the \u003cem\u003ebest document ever\u003c/em\u003e on cheap laptops!\" It's easily fooled by spam.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eThe \"Length\" Flaw:\u003c/strong\u003e A 1,000-page encyclopedia that mentions \"raven\" 10 times would get a higher score than a 1-page poem \u003cem\u003enamed\u003c/em\u003e \"The Raven\" that mentions it 5 times. The encyclopedia has more mentions, but the poem is \u003cem\u003eclearly\u003c/em\u003e more about ravens. TF-IDF just couldn't figure that out.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe needed a librarian that wasn't just fast, but \u003cem\u003esmarter\u003c/em\u003e.\u003c/p\u003e\n\u003ch4\u003eüìä How TF-IDF Works\u003c/h4\u003e\n\u003cp\u003eHere's a visual representation of TF-IDF's simple counting approach:\u003c/p\u003e\n\u003cfigure class=\"mermaid-diagram\"\u003e\u003cimg src=\"/diagrams/ai-search-evolution-diagram-1.svg\" alt=\"Diagram 1\"\u003e\u003c/figure\u003e\n\u003cp\u003eThe problem is clear: if the exact word \"soda\" doesn't appear, the document gets a score of zero. No understanding, just counting.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3\u003eüèÜ Chapter 2: The \"Smart Sorter\" Librarian (BM25)\u003c/h3\u003e\n\u003cp\u003eThis is the \"Glow-Up\" of TF-IDF. \u003cstrong\u003eBM25 (Best Matching 25)\u003c/strong\u003e is the algorithm that powered almost every major search engine for decades. It's the default for most databases today, and for good reason: it's a \u003cem\u003ephenomenally\u003c/em\u003e smart sorter.\u003c/p\u003e\n\u003cp\u003eBM25 is basically TF-IDF's kid who went to college and learned from its parent's mistakes. It fixes the two big flaws perfectly.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eThe Fix for \"Keyword Stuffing\" (Term Saturation):\u003c/strong\u003e\nBM25 is like a friend who gets bored easily.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe \u003cem\u003efirst\u003c/em\u003e time you say \"laptop,\" it's super interested (big score boost!).\u003c/li\u003e\n\u003cli\u003eThe \u003cem\u003efifth\u003c/em\u003e time, it's like, \"Yeah, I get it, 'laptop'\" (a much smaller boost).\u003c/li\u003e\n\u003cli\u003eThe \u003cem\u003e100th\u003c/em\u003e time, it's just ignoring you (zero extra score).\nThis scoring curve \"saturates,\" which makes keyword stuffing totally pointless. Problem solved.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eThe Fix for \"Length\" (Length Normalization):\u003c/strong\u003e\nBM25 is aware. It starts by calculating the \u003cem\u003eaverage document length\u003c/em\u003e of the whole collection. It knows the \"average\" document is, say, 300 words.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSo, when it sees the 1-page poem (100 words) with 5 \"raven\" mentions, it thinks, \"Whoa! 5 mentions in \u003cem\u003esuch a short document\u003c/em\u003e? This must be \u003cem\u003einsanely\u003c/em\u003e relevant!\"\u003c/li\u003e\n\u003cli\u003eWhen it sees the 1,000-page encyclopedia, it thinks, \"Only 10 'raven' mentions in a doc this huge? Meh.\"\nIt \"normalizes\" the score, giving the short, concise poem the win.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eBM25 was king for a very long time. It's fast, efficient, and gives great results.\u003c/p\u003e\n\u003cp\u003e...But it \u003cem\u003estill\u003c/em\u003e had that one, fundamental, dumb problem. It's just a counter. A \u003cem\u003ereally, really smart\u003c/em\u003e counter, but still a counter. It has no idea what words \u003cem\u003emean\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eIf you search for \"\u003cstrong\u003esoda\u003c/strong\u003e,\" it will \u003cem\u003enever\u003c/em\u003e match \"\u003cstrong\u003epop\u003c/strong\u003e.\"\nIf you search for \"\u003cstrong\u003ebeverage for a party\u003c/strong\u003e,\" it will \u003cem\u003enever\u003c/em\u003e match \"\u003cstrong\u003edrinks for a celebration\u003c/strong\u003e.\"\u003c/p\u003e\n\u003cp\u003eTo solve this, we had to leave the world of \"counting\" and enter the world of \"understanding.\" We had to bring in AI.\u003c/p\u003e\n\u003ch4\u003eüìä How BM25 Improves Upon TF-IDF\u003c/h4\u003e\n\u003cp\u003eHere's how BM25's smart weighting works:\u003c/p\u003e\n\u003cfigure class=\"mermaid-diagram\"\u003e\u003cimg src=\"/diagrams/ai-search-evolution-diagram-2.svg\" alt=\"Diagram 2\"\u003e\u003c/figure\u003e\n\u003cp\u003eBM25 is smarter, but it still can't connect \"soda\" with \"pop\" conceptually!\u003c/p\u003e\n\u003chr\u003e\n\u003ch3\u003eü§ñ Chapter 3: The \"AI Mind Reader\" (SPLADE)\u003c/h3\u003e\n\u003cp\u003eThis is the new frontier of \u003cstrong\u003eLearned Sparse Retrieval (LSR)\u003c/strong\u003e. Its most famous and effective model: \u003cstrong\u003eSPLADE (Sparse Lexical and Expansion Model)\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eThis is a total game-changer. SPLADE is built on a \u003cstrong\u003eTransformer AI model (specifically, the BERT architecture)\u003c/strong\u003e. This AI has read basically the entire internet. It doesn't just know words; it knows \u003cem\u003econcepts\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eHere's the magic, step-by-step:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eCore Mechanism:\u003c/strong\u003e SPLADE leverages the \u003cstrong\u003eMasked Language Modeling (MLM)\u003c/strong\u003e head of BERT. This is the part of the model that's trained to fill in the blanks, which forces it to understand the context of every single word.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUnderstand \u0026#x26; Expand:\u003c/strong\u003e Instead of discarding the MLM head, SPLADE uses it to predict the relevance of \u003cem\u003eevery\u003c/em\u003e word in its vocabulary (around 30,000 terms) based on the input document. When you give it \"A guide to French cheese,\" the model \u003cem\u003eexpands\u003c/em\u003e the term list to include all related concepts it learned: 'brie', 'camembert', 'gourmet', 'wine', etc.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePrune \u0026#x26; Sparsify:\u003c/strong\u003e Here's the genius part (the \"Sparse\" in SPLADE): the model is trained with strong regularization to be a minimalist. It forces the scores of 99%+ of the vocabulary to be \u003cstrong\u003ezero\u003c/strong\u003e, leaving behind \u003cem\u003eonly\u003c/em\u003e the absolute most important and descriptive \"tags\" for this document.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThe result is a \u003cstrong\u003e\"Smart Tag Cloud.\"\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA \u003cstrong\u003eBM25\u003c/strong\u003e \"tag cloud\" for that doc would just be: \u003ccode\u003e[guide, french, cheese]\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eA \u003cstrong\u003eSPLADE\u003c/strong\u003e \"tag cloud\" (its sparse vector) would be: \u003ccode\u003e[guide, french, cheese, brie, camembert, gourmet, wine, dairy]\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNow... when your user searches for \"\u003cstrong\u003ebest brie recipe\u003c/strong\u003e,\" SPLADE sees a match! Your document is found, even though it \u003cem\u003enever\u003c/em\u003e contained the word \"brie.\" The vocabulary mismatch problem is finally solved.\u003c/p\u003e\n\u003ch4\u003eüìå Not the Only Player: Learned Sparse Retrieval (LSR)\u003c/h4\u003e\n\u003cp\u003eWhile SPLADE is the most widely adopted, it is part of a broader, active research field called \u003cstrong\u003eLearned Sparse Retrieval (LSR)\u003c/strong\u003e. Other notable models you might encounter include \u003cstrong\u003euniCOIL\u003c/strong\u003e and \u003cstrong\u003eDeepImpact\u003c/strong\u003e. They all aim to achieve the same goal - neural-powered keyword search - but differ slightly in their training and approach (e.g., DeepImpact often expands documents \u003cem\u003ebefore\u003c/em\u003e applying the learned scores, while SPLADE does it end-to-end).\u003c/p\u003e\n\u003ch4\u003eüìä How SPLADE Expands Your Query\u003c/h4\u003e\n\u003cp\u003eLet's visualize how SPLADE transforms a simple query into a rich concept map:\u003c/p\u003e\n\u003cfigure class=\"mermaid-diagram\"\u003e\u003cimg src=\"/diagrams/ai-search-evolution-diagram-3.svg\" alt=\"Diagram 3\"\u003e\u003c/figure\u003e\n\u003cp\u003eNotice how SPLADE not only keeps the original terms (\"french\", \"cheese\") but intelligently adds related concepts (\"brie\", \"camembert\", \"gourmet\", \"dairy\", \"wine\") with appropriate weights. The higher the weight, the more important the term is to understanding the query.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3\u003eüí° Wait... Why Not Just Use \"AI Search\" (Dense Vectors)?\u003c/h3\u003e\n\u003cp\u003eThis is the central question. You've heard \"semantic search\" and \"dense vectors.\" If SPLADE uses AI, and semantic search uses AI, aren't they the same?\u003c/p\u003e\n\u003cp\u003eNope! They are two different AI strategies, good at \u003cem\u003eopposite\u003c/em\u003e things.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eDense Vectors (Semantic Search):\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAnalogy:\u003c/strong\u003e A \"GPS Coordinate\" for meaning, or a \"Vibe Check.\"\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e It takes your \u003cem\u003ewhole\u003c/em\u003e document and squashes its \u003cem\u003eentire\u003c/em\u003e meaning into a list of ~768 numbers, like \u003ccode\u003e[0.1, -0.4, 0.9, ...]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGood at:\u003c/strong\u003e Finding \u003cem\u003eholistic concepts\u003c/em\u003e. It knows \"sad songs\" is close to \"lyrics about a broken heart.\" It's great at finding the \"vibe.\"\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBad at:\u003c/strong\u003e \u003cem\u003eSpecificity\u003c/em\u003e. It \"averages out\" the meaning. If you search for a specific product ID like \"\u003cstrong\u003eSKU-ABC-123\u003c/strong\u003e,\" the dense vector just sees \"some product ID\" and gets confused. It \u003cem\u003eloses\u003c/em\u003e the specific keyword.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eSPLADE (Learned Sparse Search):\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eAnalogy:\u003c/strong\u003e A \"Smart Tag Cloud\" or an \"AI-powered Index.\"\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e It creates a huge list (~30,000 slots) that is \u003cem\u003emostly zeros\u003c/em\u003e but has high scores on \u003cem\u003every specific\u003c/em\u003e keywords, including its smart expansions.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGood at:\u003c/strong\u003e \u003cem\u003ePrecision\u003c/em\u003e. It \u003cem\u003eloves\u003c/em\u003e specific keywords. It will see \"\u003cstrong\u003eSKU-ABC-123\u003c/strong\u003e\" and put a \u003cem\u003emassive\u003c/em\u003e importance score on that \u003cem\u003eexact\u003c/em\u003e term, making it impossible to miss.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBad at:\u003c/strong\u003e Vague \"vibes.\" A search for \"that feeling you get on a rainy day\" would be hard for SPLADE, but easy for a dense vector.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe ultimate setup isn't one or the other. It's \u003cstrong\u003eHybrid Search\u003c/strong\u003e: using \u003cem\u003eboth\u003c/em\u003e at the same time. You get the \"vibe\" search from dense vectors and the \"precision\" search from SPLADE.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3\u003eüì¶ Putting It All Together in Your Vector DB\u003c/h3\u003e\n\u003cp\u003eThis is where a modern vector database like \u003cstrong\u003eQdrant\u003c/strong\u003e becomes so powerful. It's \u003cem\u003edesigned\u003c/em\u003e for this new, hybrid world. It doesn't force you to choose.\u003c/p\u003e\n\u003ch4\u003eüîÑ How Hybrid Search Works\u003c/h4\u003e\n\u003cp\u003eHere's how Qdrant executes a hybrid search, combining dense and sparse vectors with RRF fusion:\u003c/p\u003e\n\u003cfigure class=\"mermaid-diagram\"\u003e\u003cimg src=\"/diagrams/ai-search-evolution-diagram-4.svg\" alt=\"Diagram 4\"\u003e\u003c/figure\u003e\n\u003cp\u003eThe beauty of hybrid search is that it runs both searches in parallel, then intelligently combines the results. Documents that appear highly ranked in \u003cem\u003eboth\u003c/em\u003e searches get a significant boost, ensuring you get the most relevant results.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3\u003eüéØ Beyond Retrieval: The Final Step is Reranking\u003c/h3\u003e\n\u003cp\u003eYou now have a Hybrid Search system that is both broad (high \u003cstrong\u003eRecall\u003c/strong\u003e from Dense) and specific (high \u003cstrong\u003ePrecision\u003c/strong\u003e from Sparse). This is called \u003cstrong\u003eFirst-Stage Retrieval\u003c/strong\u003e - you've successfully identified a short list of, say, 50 potential documents.\u003c/p\u003e\n\u003cp\u003eBut for a true production-grade system (especially for Retrieval-Augmented Generation, or RAG), we need one more step: \u003cstrong\u003eReranking\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eReranking is the quality control filter. It is done by a highly accurate but slow model called a \u003cstrong\u003eCross-Encoder\u003c/strong\u003e.\u003c/p\u003e\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth align=\"left\"\u003eConcept\u003c/th\u003e\u003cth align=\"left\"\u003eThe Analogy\u003c/th\u003e\u003cth align=\"left\"\u003eThe Technical Difference\u003c/th\u003e\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd align=\"left\"\u003e\u003cstrong\u003eFirst-Stage Models\u003c/strong\u003e (Dense/SPLADE)\u003c/td\u003e\u003ctd align=\"left\"\u003e\u003cstrong\u003eThe Matchmaker:\u003c/strong\u003e They look at your query and your document \u003cstrong\u003eseparately\u003c/strong\u003e, scoring them only on vector similarity. Fast, but lacks nuance.\u003c/td\u003e\u003ctd align=\"left\"\u003e\u003cstrong\u003eSeparate Encoding:\u003c/strong\u003e Query and Document are encoded into vectors independently.\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd align=\"left\"\u003e\u003cstrong\u003eThe Problem\u003c/strong\u003e\u003c/td\u003e\u003ctd align=\"left\"\u003e\u003cstrong\u003eQuery:\u003c/strong\u003e \"Why is \u003cstrong\u003ebrie\u003c/strong\u003e the best cheese for \u003cstrong\u003ewine\u003c/strong\u003e?\"\u003c/td\u003e\u003ctd align=\"left\"\u003eHybrid search might find a document that mentions \u003cem\u003ebrie\u003c/em\u003e highly and another that mentions \u003cem\u003ewine\u003c/em\u003e highly, but misses the document that explicitly links the two.\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd align=\"left\"\u003e\u003cstrong\u003eReranking\u003c/strong\u003e (Cross-Encoder)\u003c/td\u003e\u003ctd align=\"left\"\u003e\u003cstrong\u003eThe Literary Critic:\u003c/strong\u003e It reads your query and the document \u003cstrong\u003etogether\u003c/strong\u003e, analyzing how every word in the query interacts with every word in the document. Slow, but highly nuanced.\u003c/td\u003e\u003ctd align=\"left\"\u003e\u003cstrong\u003eJoint Encoding:\u003c/strong\u003e Query and Document are fed into the Transformer network at the same time.\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd align=\"left\"\u003e\u003cstrong\u003eThe Solution\u003c/strong\u003e\u003c/td\u003e\u003ctd align=\"left\"\u003eThe Cross-Encoder instantly sees that the document titled \u003cem\u003e\"Pairing \u003cstrong\u003eBrie\u003c/strong\u003e with Chardonnay \u003cstrong\u003eWine\u003c/strong\u003e\"\u003c/em\u003e is the \u003cstrong\u003eperfect\u003c/strong\u003e answer, even if the similarity score from the first stage wasn't the absolute highest.\u003c/td\u003e\u003ctd align=\"left\"\u003eIt correctly promotes the most contextually relevant document to the #1 spot.\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003eHybrid Search gets the candidates; Reranking picks the winner.\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3\u003eThe Journey Continues\u003c/h3\u003e\n\u003cp\u003eWe've come a long, long way from just counting words. The \"search problem\" is finally being solved by combining these ideas. We started with TF-IDF (a dumb counter), got smarter with BM25 (a great sorter), and now, with AI models like SPLADE, we're teaching search to \u003cem\u003eunderstand\u003c/em\u003e what we mean, not just what we say.\u003c/p\u003e\n\u003cp\u003eThe future isn't dense vs. sparse. It's \u003cem\u003eboth\u003c/em\u003e, with a final, highly-accurate \u003cstrong\u003ereranker\u003c/strong\u003e to guarantee quality.\u003c/p\u003e"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"$L15\",null,{\"slug\":\"ai-search-evolution\"}],[\"$\",\"$L16\",null,{}],[\"$\",\"article\",null,{\"className\":\"mx-auto flex w-full max-w-3xl flex-col gap-10 px-6 pt-12 pb-28\",\"children\":[[\"$\",\"nav\",null,{\"aria-label\":\"Breadcrumb\",\"children\":[\"$\",\"ol\",null,{\"className\":\"flex flex-wrap items-center gap-1 text-sm text-muted-foreground\",\"children\":[[\"$\",\"li\",\"/\",{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"$L17\",null,{\"href\":\"/\",\"className\":\"hover:text-accent\",\"children\":\"Home\"}],[\"$\",\"span\",null,{\"aria-hidden\":true,\"children\":\"/\"}]]}],[\"$\",\"li\",\"/#posts\",{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"$L17\",null,{\"href\":{\"pathname\":\"/\",\"hash\":\"posts\"},\"className\":\"hover:text-accent\",\"children\":\"Posts\"}],[\"$\",\"span\",null,{\"aria-hidden\":true,\"children\":\"/\"}]]}],[\"$\",\"li\",\"/posts/ai-search-evolution\",{\"className\":\"flex items-center gap-1\",\"children\":[[\"$\",\"$L17\",null,{\"href\":\"/posts/ai-search-evolution\",\"className\":\"hover:text-accent\",\"children\":\"Beyond the Keyword: How AI Taught Search to Understand You\"}],null]}]]}]}],[\"$\",\"header\",null,{\"className\":\"space-y-4\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-xs uppercase tracking-[0.3em] text-accent\",\"children\":\"Article\"}],[\"$\",\"h1\",null,{\"className\":\"text-3xl font-semibold leading-tight sm:text-4xl\",\"children\":\"Beyond the Keyword: How AI Taught Search to Understand You\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-3 text-sm text-muted-foreground\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-11-14T00:00:00.000Z\",\"children\":\"Nov 14, 2025\"}],[\"$\",\"span\",null,{\"aria-hidden\":true,\"children\":\"‚Ä¢\"}],[\"$\",\"span\",null,{\"children\":\"11 min read\"}],[\"$\",\"span\",null,{\"aria-hidden\":true,\"children\":\"‚Ä¢\"}],[\"$\",\"$L17\",null,{\"href\":\"/about\",\"className\":\"font-medium text-foreground transition-colors hover:text-accent\",\"children\":\"Vinay Punera\"}],null]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2\",\"children\":[[\"$\",\"span\",\"ai-search\",{\"className\":\"rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide\",\"children\":\"ai-search\"}],[\"$\",\"span\",\"splade\",{\"className\":\"rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide\",\"children\":\"splade\"}],[\"$\",\"span\",\"bm25\",{\"className\":\"rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide\",\"children\":\"bm25\"}],[\"$\",\"span\",\"tf-idf\",{\"className\":\"rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide\",\"children\":\"tf-idf\"}],[\"$\",\"span\",\"vectors\",{\"className\":\"rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide\",\"children\":\"vectors\"}],[\"$\",\"span\",\"sparse-vectors\",{\"className\":\"rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide\",\"children\":\"sparse-vectors\"}],[\"$\",\"span\",\"dense-vectors\",{\"className\":\"rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide\",\"children\":\"dense-vectors\"}],[\"$\",\"span\",\"qdrant\",{\"className\":\"rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide\",\"children\":\"qdrant\"}],[\"$\",\"span\",\"rag\",{\"className\":\"rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide\",\"children\":\"rag\"}],[\"$\",\"span\",\"nlp\",{\"className\":\"rounded-full border border-border px-3 py-1 text-xs uppercase tracking-wide\",\"children\":\"nlp\"}]]}]]}],[\"$\",\"$L18\",null,{\"postTitle\":\"Beyond the Keyword: How AI Taught Search to Understand You\",\"postSlug\":\"ai-search-evolution\",\"audio\":{\"src\":\"/audio/ai-search-evolution.m4a\",\"title\":\"AI narration\",\"duration\":\"05:00\",\"mimeType\":\"audio/mp4\"}}],[\"$\",\"$L19\",null,{}],[\"$\",\"div\",null,{\"className\":\"overflow-hidden rounded-3xl border border-border bg-muted\",\"children\":[\"$\",\"$L1a\",null,{\"src\":\"/illustrations/ai-search-evolution.svg\",\"alt\":\"An abstract image showing a simple keyword 'pop' evolving into a complex, connected concept of 'soda' and 'beverage'.\",\"width\":1200,\"height\":630,\"sizes\":\"(max-width: 768px) 100vw, 768px\",\"className\":\"h-auto w-full object-cover\",\"priority\":true,\"placeholder\":\"$undefined\",\"blurDataURL\":\"$undefined\"}]}],[\"$\",\"div\",null,{\"className\":\"prose prose-neutral dark:prose-invert max-w-none\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$1b\"}}]}],\"$L1c\"]}]]\n"])</script><script>self.__next_f.push([1,"1d:I[6023,[\"2201\",\"static/chunks/2201-6f6797369dbd70e4.js\",\"1356\",\"static/chunks/1356-1fb83b63ccda55b7.js\",\"8005\",\"static/chunks/8005-36f473f8046dae16.js\",\"5858\",\"static/chunks/app/posts/%5Bslug%5D/page-9925e7bd02be95a8.js\"],\"ShareButtons\"]\n"])</script><script>self.__next_f.push([1,"1c:[\"$\",\"footer\",null,{\"className\":\"flex flex-col gap-6 border-t border-border pt-6\",\"children\":[[\"$\",\"$L1d\",null,{\"slug\":\"ai-search-evolution\",\"title\":\"Beyond the Keyword: How AI Taught Search to Understand You\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":\"Enjoyed this read? Share it with your network, or reach out via the about page for collaboration or to just say hi.\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-col gap-4 border-t border-border pt-6\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-xs uppercase tracking-[0.3em] text-muted-foreground\",\"children\":\"Keep reading\"}],[\"$\",\"nav\",null,{\"className\":\"flex flex-col items-stretch gap-3 sm:flex-row sm:items-center sm:justify-between\",\"children\":[[\"$\",\"$L17\",null,{\"href\":\"/posts/v8-isolates-explainer-p1\",\"className\":\"group inline-flex flex-1 items-center gap-2 rounded-full border border-border px-4 py-2 text-sm transition hover:border-accent hover:text-accent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-accent\",\"children\":[[\"$\",\"span\",null,{\"aria-hidden\":true,\"children\":\"‚Üê\"}],[\"$\",\"span\",null,{\"className\":\"flex flex-col text-left\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-[11px] uppercase tracking-widest text-muted-foreground\",\"children\":\"Previous\"}],[\"$\",\"span\",null,{\"className\":\"font-medium text-foreground group-hover:text-accent\",\"children\":\"Deep Dive into V8 and V8 Isolates: The Engine and the Sandbox (Part 1)\"}]]}]]}],[\"$\",\"$L17\",null,{\"href\":\"/posts/p2p-paradox\",\"className\":\"group inline-flex flex-1 items-center justify-end gap-2 rounded-full border border-border px-4 py-2 text-sm transition hover:border-accent hover:text-accent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-accent sm:justify-end\",\"children\":[[\"$\",\"span\",null,{\"className\":\"flex flex-col text-right\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-[11px] uppercase tracking-widest text-muted-foreground\",\"children\":\"Next\"}],[\"$\",\"span\",null,{\"className\":\"font-medium text-foreground group-hover:text-accent\",\"children\":\"The P2P Paradox: Why You Need a Server to go Serverless\"}]]}],[\"$\",\"span\",null,{\"aria-hidden\":true,\"children\":\"‚Üí\"}]]}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nc:null\n"])</script><script>self.__next_f.push([1,"1e:I[80622,[],\"IconMark\"]\n"])</script><script>self.__next_f.push([1,"e:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Beyond the Keyword: How AI Taught Search to Understand You\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"We've all been there: you search for 'soda' but the app only knows 'pop'. This is the search problem. Let's go on a journey from simple keyword counting (TF-IDF) to smarter ranking (BM25) and finally to AI that gets you (SPLADE).\"}],[\"$\",\"meta\",\"2\",{\"property\":\"og:title\",\"content\":\"Beyond the Keyword: How AI Taught Search to Understand You\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:description\",\"content\":\"We've all been there: you search for 'soda' but the app only knows 'pop'. This is the search problem. Let's go on a journey from simple keyword counting (TF-IDF) to smarter ranking (BM25) and finally to AI that gets you (SPLADE).\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:image\",\"content\":\"https://vinay.stealthbit.in/illustrations/ai-search-evolution.svg\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:image:alt\",\"content\":\"An abstract image showing a simple keyword 'pop' evolving into a complex, connected concept of 'soda' and 'beverage'.\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"9\",{\"property\":\"article:published_time\",\"content\":\"2025-11-14T00:00:00.000Z\"}],[\"$\",\"meta\",\"10\",{\"property\":\"article:tag\",\"content\":\"ai-search\"}],[\"$\",\"meta\",\"11\",{\"property\":\"article:tag\",\"content\":\"splade\"}],[\"$\",\"meta\",\"12\",{\"property\":\"article:tag\",\"content\":\"bm25\"}],[\"$\",\"meta\",\"13\",{\"property\":\"article:tag\",\"content\":\"tf-idf\"}],[\"$\",\"meta\",\"14\",{\"property\":\"article:tag\",\"content\":\"vectors\"}],[\"$\",\"meta\",\"15\",{\"property\":\"article:tag\",\"content\":\"sparse-vectors\"}],[\"$\",\"meta\",\"16\",{\"property\":\"article:tag\",\"content\":\"dense-vectors\"}],[\"$\",\"meta\",\"17\",{\"property\":\"article:tag\",\"content\":\"qdrant\"}],[\"$\",\"meta\",\"18\",{\"property\":\"article:tag\",\"content\":\"rag\"}],[\"$\",\"meta\",\"19\",{\"property\":\"article:tag\",\"content\":\"nlp\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"21\",{\"name\":\"twitter:title\",\"content\":\"Beyond the Keyword: How AI Taught Search to Understand You\"}],[\"$\",\"meta\",\"22\",{\"name\":\"twitter:description\",\"content\":\"We've all been there: you search for 'soda' but the app only knows 'pop'. This is the search problem. Let's go on a journey from simple keyword counting (TF-IDF) to smarter ranking (BM25) and finally to AI that gets you (SPLADE).\"}],[\"$\",\"meta\",\"23\",{\"name\":\"twitter:image\",\"content\":\"https://vinay.stealthbit.in/illustrations/ai-search-evolution.svg\"}],[\"$\",\"link\",\"24\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"link\",\"25\",{\"rel\":\"icon\",\"href\":\"/icon.svg?b0cfa693b1818954\",\"type\":\"image/svg+xml\",\"sizes\":\"any\"}],[\"$\",\"$L1e\",\"26\",{}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"13:\"$e:metadata\"\n"])</script></body></html>